128*256*256
########################Schedule candidate########################
parallel
evaluation time: 0.0021620950
unroll
evaluation time: 0.0001331500
packing
evaluation time: 0.0001521050
write cache
evaluation time: 0.0001452050
#######################find best schedule#########################
Minimum Value: 0.0001331500
unroll
Numpy running time: 0.000029
speedup= 0.2149230185
##################################################################
best schedule method:  <function Gemm_tv2_reorder2_3_vec1_para1_unrollv1_config_define at 0x7fa95b259048>
ConfigSpace (len=648, space_map=
   0 tile_x: Split(policy=factors, product=128, num_outputs=2) len=8
   1 tile_y: Split(policy=factors, product=256, num_outputs=2) len=9
   2 tile_k: Split(policy=factors, product=256, num_outputs=2) len=9
)
XGBoost:
 Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/648) | 0.00 s Current/Best:   11.59/  17.65 GFLOPS | Progress: (8/648) | 13.76 s Current/Best:   38.20/  46.54 GFLOPS | Progress: (16/648) | 26.09 s Current/Best:    3.45/  57.96 GFLOPS | Progress: (24/648) | 39.17 s Current/Best:    9.78/  57.96 GFLOPS | Progress: (32/648) | 51.95 s Current/Best:   41.99/  57.96 GFLOPS | Progress: (40/648) | 64.95 s Current/Best:   22.30/  63.22 GFLOPS | Progress: (48/648) | 77.50 s Current/Best:    1.32/  63.22 GFLOPS | Progress: (56/648) | 90.50 s
_____________fit______________
fit count: 1
x_train shape: (64, 252)
y_train shape: (64,)
find maximums
predict count: 1
feas shape: (128, 252)
result[:1]: [3.316667]
points shape: (128,)
scores shape: (128,)
2:maxmums: [385, 249, 322, 306, 248, 448, 75, 389, 147, 401, 378, 3, 83, 317, 162, 316, 532, 218, 258, 462, 308, 74, 524, 453, 328, 296, 382, 163, 525, 146, 26, 82, 579, 97, 591, 435, 6, 595, 20, 24, 291, 299, 530, 522, 508, 519, 105, 391, 594, 576, 517, 529, 442, 254, 7, 33, 261, 114, 506, 399, 439, 29, 14, 267]
 Current/Best:   16.03/  63.22 GFLOPS | Progress: (64/648) | 103.57 s Current/Best:   42.72/  63.22 GFLOPS | Progress: (72/648) | 107.32 s Current/Best:   55.95/  63.22 GFLOPS | Progress: (80/648) | 113.34 s Current/Best:   41.35/  63.22 GFLOPS | Progress: (88/648) | 120.30 s Current/Best:   23.26/  63.22 GFLOPS | Progress: (96/648) | 125.05 s Current/Best:   13.90/  63.22 GFLOPS | Progress: (104/648) | 132.05 s Current/Best:   21.81/  63.22 GFLOPS | Progress: (112/648) | 138.58 s Current/Best:   13.96/  63.22 GFLOPS | Progress: (120/648) | 145.32 s
_____________fit______________
fit count: 2
x_train shape: (128, 252)
y_train shape: (128,)
find maximums
predict count: 2
feas shape: (128, 252)
result[:1]: [0.62036455]
points shape: (128,)
scores shape: (128,)
2:maxmums: [255, 263, 406, 191, 303]
 Current/Best:    9.65/  63.22 GFLOPS | Progress: (128/648) | 158.67 s Current/Best:   26.30/  63.22 GFLOPS | Progress: (136/648) | 171.65 s Current/Best:   13.08/  65.79 GFLOPS | Progress: (144/648) | 184.40 s Current/Best:    0.86/  65.79 GFLOPS | Progress: (152/648) | 197.42 s Current/Best:    9.76/  65.79 GFLOPS | Progress: (160/648) | 205.92 s Current/Best:   17.14/  65.79 GFLOPS | Progress: (168/648) | 218.53 s Current/Best:   31.37/  65.79 GFLOPS | Progress: (176/648) | 231.13 s Current/Best:   39.14/  65.79 GFLOPS | Progress: (184/648) | 243.43 s
_____________fit______________
fit count: 3
x_train shape: (192, 252)
y_train shape: (192,)
find maximums
predict count: 3
feas shape: (128, 252)
result[:1]: [2.1639948]
points shape: (128,)
scores shape: (128,)
2:maxmums: [406, 183]
 Current/Best:    0.83/  65.79 GFLOPS | Progress: (192/648) | 256.85 s Current/Best:    1.15/  65.79 GFLOPS | Progress: (200/648) | 270.08 s Current/Best:    1.27/  65.79 GFLOPS | Progress: (208/648) | 283.03 s Current/Best:   26.09/  65.79 GFLOPS | Progress: (216/648) | 287.54 s Current/Best:   26.39/  65.79 GFLOPS | Progress: (224/648) | 299.43 s Current/Best:   30.49/  65.79 GFLOPS | Progress: (232/648) | 312.14 s Current/Best:   25.72/  65.79 GFLOPS | Progress: (240/648) | 319.99 s Current/Best:   25.45/  65.79 GFLOPS | Progress: (248/648) | 333.23 s
_____________fit______________
fit count: 4
x_train shape: (256, 252)
y_train shape: (256,)
find maximums
predict count: 4
feas shape: (128, 252)
result[:1]: [1.6241122]
points shape: (128,)
scores shape: (128,)
2:maxmums: [406, 183, 191, 14]
 Current/Best:    6.78/  65.79 GFLOPS | Progress: (256/648) | 346.58 s Current/Best:   22.54/  65.79 GFLOPS | Progress: (264/648) | 359.21 s Current/Best:   18.64/  65.79 GFLOPS | Progress: (272/648) | 371.44 s Current/Best:   19.11/  65.79 GFLOPS | Progress: (280/648) | 383.94 s Current/Best:    2.11/  65.79 GFLOPS | Progress: (288/648) | 396.57 s Current/Best:   15.81/  65.79 GFLOPS | Progress: (296/648) | 409.18 s Current/Best:   34.42/  65.79 GFLOPS | Progress: (304/648) | 421.65 s Current/Best:   10.16/  65.79 GFLOPS | Progress: (312/648) | 434.43 s
_____________fit______________
fit count: 5
x_train shape: (320, 252)
y_train shape: (320,)
find maximums
predict count: 5
feas shape: (128, 252)
result[:1]: [1.4278587]
points shape: (128,)
scores shape: (128,)
2:maxmums: [183, 191]
 Current/Best:    1.53/  65.79 GFLOPS | Progress: (320/648) | 448.11 s Current/Best:   38.67/  65.79 GFLOPS | Progress: (328/648) | 460.89 s Current/Best:   16.19/  65.79 GFLOPS | Progress: (336/648) | 473.43 s Current/Best:    4.36/  65.79 GFLOPS | Progress: (344/648) | 485.85 s Current/Best:    4.39/  65.79 GFLOPS | Progress: (352/648) | 498.12 s Current/Best:   60.00/  65.79 GFLOPS | Progress: (360/648) | 510.82 s Current/Best:   13.28/  70.19 GFLOPS | Progress: (368/648) | 523.32 s Current/Best:    7.54/  70.19 GFLOPS | Progress: (376/648) | 535.80 s
_____________fit______________
fit count: 6
x_train shape: (384, 252)
y_train shape: (384,)
find maximums
predict count: 6
feas shape: (128, 252)
result[:1]: [1.4379448]
points shape: (128,)
scores shape: (128,)
2:maxmums: [183, 191]
 Current/Best:   28.96/  70.19 GFLOPS | Progress: (384/648) | 548.69 s Current/Best:   22.21/  70.19 GFLOPS | Progress: (392/648) | 561.36 s Current/Best:   10.41/  70.19 GFLOPS | Progress: (400/648) | 574.27 s Current/Best:   16.87/  70.19 GFLOPS | Progress: (408/648) | 586.65 s Current/Best:   10.78/  70.19 GFLOPS | Progress: (416/648) | 600.02 s Current/Best:   11.21/  70.19 GFLOPS | Progress: (424/648) | 612.69 s Current/Best:   15.31/  70.19 GFLOPS | Progress: (432/648) | 625.25 s Current/Best:    9.77/  70.19 GFLOPS | Progress: (440/648) | 637.83 s
_____________fit______________
fit count: 7
x_train shape: (448, 252)
y_train shape: (448,)
find maximums
predict count: 7
feas shape: (128, 252)
result[:1]: [1.2405176]
points shape: (128,)
scores shape: (128,)
2:maxmums: [183, 191, 190]
 Current/Best:   12.35/  70.19 GFLOPS | Progress: (448/648) | 646.04 s Current/Best:   42.06/  70.19 GFLOPS | Progress: (456/648) | 658.46 s Current/Best:   14.43/  70.19 GFLOPS | Progress: (464/648) | 670.57 s Current/Best:   23.60/  70.19 GFLOPS | Progress: (472/648) | 682.42 s Current/Best:   29.08/  70.19 GFLOPS | Progress: (480/648) | 692.70 s Current/Best:    1.43/  70.19 GFLOPS | Progress: (488/648) | 705.22 s Current/Best:    9.94/  70.19 GFLOPS | Progress: (496/648) | 718.17 s Current/Best:    3.06/  70.19 GFLOPS | Progress: (504/648) | 731.05 s
_____________fit______________
fit count: 8
x_train shape: (512, 252)
y_train shape: (512,)
find maximums
predict count: 8
feas shape: (128, 252)
result[:1]: [1.4990696]
points shape: (128,)
scores shape: (128,)
2:maxmums: [191]
 Current/Best:   28.68/  70.19 GFLOPS | Progress: (512/648) | 744.08 s Current/Best:   20.27/  70.19 GFLOPS | Progress: (520/648) | 756.82 s Current/Best:   15.69/  70.19 GFLOPS | Progress: (528/648) | 769.52 s Current/Best:   34.41/  70.19 GFLOPS | Progress: (536/648) | 782.42 s Current/Best:    7.45/  70.19 GFLOPS | Progress: (544/648) | 795.26 s Current/Best:   17.20/  70.19 GFLOPS | Progress: (552/648) | 807.65 s Current/Best:   70.06/  70.19 GFLOPS | Progress: (560/648) | 820.54 s Current/Best:    6.03/  70.19 GFLOPS | Progress: (568/648) | 833.63 s
_____________fit______________
fit count: 9
x_train shape: (576, 252)
y_train shape: (576,)
find maximums
predict count: 9
feas shape: (128, 252)
result[:1]: [1.4027636]
points shape: (128,)
scores shape: (128,)
2:maxmums: [191]
 Current/Best:   32.09/  70.19 GFLOPS | Progress: (576/648) | 846.54 s Current/Best:    5.50/  70.19 GFLOPS | Progress: (584/648) | 859.10 s Current/Best:    1.10/  70.19 GFLOPS | Progress: (592/648) | 871.92 s Current/Best:    1.53/  70.19 GFLOPS | Progress: (600/648) | 884.13 s Current/Best:   13.86/  70.19 GFLOPS | Progress: (608/648) | 896.72 s Current/Best:   23.27/  70.19 GFLOPS | Progress: (616/648) | 909.11 s Current/Best:   11.71/  70.19 GFLOPS | Progress: (624/648) | 922.03 s Current/Best:    4.70/  70.19 GFLOPS | Progress: (632/648) | 934.74 s
_____________fit______________
fit count: 10
x_train shape: (640, 252)
y_train shape: (640,)
find maximums
predict count: 10
feas shape: (128, 252)
result[:1]: [1.0911272]
points shape: (128,)
scores shape: (128,)
2:maxmums: [191]
 Current/Best:    7.69/  70.19 GFLOPS | Progress: (640/648) | 947.44 s Current/Best:   17.24/  70.19 GFLOPS | Progress: (648/648) | 960.54 s Done.
fea type: itervar
feature_cache type: <class 'tvm.autotvm.tuner.model_based_tuner.FeatureCache'>
feature cache context type: <class 'dict'>
feature_cache_context len: 641
feature_cache_context keys: dict_keys([10, 131, 535, 366, 413, 192, 341, 28, 534, 13, 331, 259, 545, 492, 558, 250, 184, 134, 404, 456, 286, 445, 597, 199, 136, 607, 593, 629, 35, 226, 379, 434, 274, 5, 624, 96, 55, 202, 381, 243, 623, 512, 589, 557, 395, 127, 237, 319, 645, 64, 189, 174, 23, 628, 124, 214, 206, 418, 537, 339, 358, 278, 354, 107, 3, 517, 6, 7, 519, 522, 524, 525, 14, 529, 530, 532, 20, 24, 536, 26, 540, 29, 30, 543, 541, 33, 544, 548, 37, 49, 566, 575, 576, 65, 579, 69, 74, 75, 591, 82, 83, 594, 595, 97, 609, 613, 105, 625, 114, 626, 121, 634, 122, 636, 640, 132, 137, 141, 146, 147, 162, 163, 183, 190, 191, 193, 198, 215, 218, 230, 248, 249, 254, 255, 258, 261, 263, 267, 270, 285, 291, 296, 299, 303, 306, 308, 316, 317, 322, 328, 340, 342, 345, 356, 378, 382, 385, 389, 391, 399, 401, 406, 411, 417, 419, 430, 435, 439, 442, 448, 453, 462, 472, 482, 483, 485, 487, 488, 490, 497, 506, 508, 580, 507, 615, 12, 39, 444, 504, 480, 154, 469, 459, 309, 460, 351, 612, 93, 407, 313, 92, 428, 343, 62, 565, 586, 457, 454, 300, 43, 279, 115, 509, 572, 235, 271, 54, 11, 587, 135, 386, 377, 630, 98, 464, 282, 422, 329, 610, 436, 238, 334, 465, 91, 225, 31, 36, 185, 618, 643, 71, 106, 338, 380, 25, 528, 63, 542, 169, 81, 458, 387, 126, 133, 505, 361, 584, 335, 216, 72, 511, 179, 196, 491, 421, 415, 639, 84, 232, 538, 247, 397, 360, 176, 240, 604, 355, 172, 113, 18, 207, 140, 148, 178, 119, 79, 403, 601, 61, 320, 327, 312, 272, 269, 501, 323, 257, 326, 447, 112, 414, 638, 440, 301, 150, 384, 477, 359, 325, 631, 80, 242, 515, 9, 567, 277, 503, 526, 203, 581, 173, 408, 547, 52, 475, 437, 167, 516, 471, 553, 533, 621, 441, 426, 293, 371, 608, 346, 262, 57, 450, 109, 390, 42, 159, 596, 2, 518, 76, 104, 38, 149, 101, 619, 95, 212, 318, 284, 168, 374, 111, 451, 236, 4, 353, 560, 229, 311, 546, 151, 47, 304, 347, 73, 117, 68, 570, 429, 424, 0, 409, 116, 44, 573, 266, 253, 590, 41, 224, 161, 388, 295, 352, 244, 88, 468, 156, 365, 569, 260, 283, 402, 78, 427, 56, 157, 476, 209, 177, 561, 556, 217, 204, 562, 241, 252, 315, 89, 431, 152, 87, 100, 138, 449, 51, 527, 171, 493, 372, 321, 363, 496, 188, 22, 59, 314, 513, 452, 195, 616, 34, 637, 324, 332, 123, 364, 466, 200, 486, 605, 77, 622, 273, 99, 222, 181, 70, 425, 539, 194, 367, 103, 221, 305, 139, 27, 370, 53, 67, 362, 420, 600, 118, 186, 614, 592, 405, 170, 552, 611, 223, 17, 307, 330, 160, 498, 633, 606, 416, 583, 153, 455, 264, 394, 86, 588, 292, 551, 602, 549, 288, 50, 205, 166, 433, 585, 563, 128, 500, 110, 85, 213, 165, 489, 158, 647, 463, 467, 481, 102, 40, 228, 432, 644, 175, 231, 298, 578, 48, 187, 348, 514, 246, 45, 251, 423, 368, 336, 531, 58, 94, 478, 344, 233, 108, 574, 297, 523, 302, 129, 375, 642, 180, 256, 349, 294, 130, 19, 234, 396, 16, 310, 337, 412, 461, 220, 568, 144, 275, 143, 571, 265, 555, 398, 635, 90, 32, 598, 564, 392, 554, 502, 603, 125, 443, 219, 494, 289, 15, 577, 208, 627, 393, 641, 164, 369, 60, 357, 617, 470, 376, 400, 211, 281, 495, 350, 520, 1, 599, 227, 383, 479, 333, 280, 446, 473, 521, 155, 484, 474, 46, 210, 410, 201, 120, 182, 8, 620, 268, 510, 197, 646, 559, 582, 373, 499, 287, 245, 239, 145, 21])
task config space map: OrderedDict([('tile_x', Split(policy=factors, product=128, num_outputs=2) len=8), ('tile_y', Split(policy=factors, product=256, num_outputs=2) len=9), ('tile_k', Split(policy=factors, product=256, num_outputs=2) len=9)])
trails [191]
plan size: 64
diversity_filter_ratio: None
space ConfigSpace (len=648, space_map=
   0 tile_x: Split(policy=factors, product=128, num_outputs=2) len=8
   1 tile_y: Split(policy=factors, product=256, num_outputs=2) len=9
   2 tile_k: Split(policy=factors, product=256, num_outputs=2) len=9
)
task: Task(func_name=Gemm_tv2_reorder2_3_vec1_para1_unrollv1_config_define, args=(256, 256, 128, 'float32'), kwargs={}, workload=None)
task config space: ConfigSpace (len=648, space_map=
   0 tile_x: Split(policy=factors, product=128, num_outputs=2) len=8
   1 tile_y: Split(policy=factors, product=256, num_outputs=2) len=9
   2 tile_k: Split(policy=factors, product=256, num_outputs=2) len=9
)
flops max: 70191682704.3762
best_iter 365
tuner param: {}
tuner dims: [8, 9, 9]
xs: [10, 131, 535, 366, 413, 192, 341, 28, 534, 13, 331, 259, 545, 492, 558, 250, 184, 134, 404, 456, 286, 445, 597, 199, 136, 607, 593, 629, 35, 226, 379, 434, 274, 5, 624, 96, 55, 202, 381, 243, 623, 512, 589, 557, 395, 127, 237, 319, 645, 64, 189, 174, 23, 628, 124, 214, 206, 418, 537, 339, 358, 278, 354, 107, 385, 249, 322, 306, 248, 448, 75, 389, 147, 401, 378, 3, 83, 317, 162, 316, 532, 218, 258, 462, 308, 74, 524, 453, 328, 296, 382, 163, 525, 146, 26, 82, 579, 97, 591, 435, 6, 595, 20, 24, 291, 299, 530, 522, 508, 519, 105, 391, 594, 576, 517, 529, 442, 254, 7, 33, 261, 114, 506, 399, 439, 580, 507, 615, 255, 263, 12, 39, 444, 504, 480, 154, 469, 459, 309, 460, 351, 30, 612, 93, 230, 407, 313, 92, 428, 343, 62, 565, 586, 457, 454, 300, 43, 279, 115, 509, 572, 235, 271, 54, 11, 587, 634, 411, 135, 487, 386, 377, 630, 98, 464, 282, 422, 329, 610, 436, 238, 334, 465, 356, 91, 225, 31, 36, 185, 618, 643, 71, 106, 338, 380, 25, 340, 528, 490, 63, 542, 169, 81, 458, 303, 387, 126, 133, 505, 361, 584, 335, 216, 72, 511, 179, 196, 491, 421, 415, 639, 84, 232, 538, 247, 397, 360, 176, 193, 240, 604, 355, 172, 113, 18, 207, 121, 140, 148, 178, 119, 65, 79, 403, 601, 61, 320, 327, 312, 272, 269, 501, 323, 257, 326, 447, 406, 112, 414, 29, 638, 440, 301, 150, 384, 477, 359, 325, 631, 80, 242, 515, 215, 9, 485, 626, 567, 277, 503, 526, 203, 581, 173, 408, 547, 636, 52, 475, 437, 167, 516, 471, 553, 533, 621, 441, 426, 293, 371, 608, 346, 262, 57, 450, 109, 390, 609, 42, 159, 596, 2, 518, 76, 104, 38, 149, 101, 619, 95, 212, 318, 49, 284, 168, 374, 111, 285, 451, 236, 4, 353, 132, 560, 548, 229, 311, 546, 151, 47, 304, 347, 73, 430, 117, 68, 570, 429, 424, 0, 409, 116, 44, 573, 266, 253, 590, 41, 224, 161, 388, 544, 295, 352, 244, 88, 468, 156, 365, 569, 260, 283, 14, 402, 78, 427, 56, 640, 157, 122, 476, 209, 177, 561, 556, 217, 488, 204, 562, 241, 252, 315, 89, 431, 152, 87, 100, 138, 449, 51, 527, 171, 493, 372, 321, 363, 496, 419, 188, 22, 59, 314, 513, 452, 195, 616, 34, 637, 324, 332, 123, 364, 466, 200, 486, 605, 536, 77, 622, 273, 99, 222, 181, 267, 70, 425, 539, 345, 194, 367, 103, 221, 305, 139, 27, 370, 53, 67, 362, 420, 600, 118, 186, 625, 614, 592, 405, 170, 552, 611, 223, 482, 575, 270, 17, 307, 330, 160, 498, 633, 606, 416, 543, 583, 153, 455, 264, 394, 86, 588, 472, 292, 551, 602, 549, 288, 50, 198, 205, 166, 69, 433, 183, 585, 563, 128, 500, 110, 85, 483, 213, 165, 489, 158, 342, 647, 463, 467, 481, 102, 40, 417, 228, 432, 644, 175, 231, 298, 578, 48, 187, 348, 514, 246, 45, 251, 423, 368, 336, 531, 58, 190, 94, 566, 478, 344, 233, 108, 574, 297, 523, 302, 129, 497, 375, 642, 180, 256, 349, 540, 294, 130, 19, 234, 396, 16, 310, 337, 412, 461, 220, 568, 144, 137, 275, 143, 571, 265, 555, 398, 635, 90, 32, 598, 564, 392, 554, 502, 603, 125, 443, 219, 494, 289, 15, 577, 208, 627, 393, 641, 164, 369, 60, 357, 541, 617, 470, 376, 400, 211, 281, 495, 350, 520, 1, 141, 599, 227, 383, 479, 333, 280, 446, 473, 521, 155, 484, 474, 46, 210, 410, 201, 120, 182, 8, 620, 37, 268, 510, 197, 646, 559, 582, 373, 499, 287, 613, 245, 239, 145, 21, 191, 632, 550, 142, 66, 276, 438, 290]
ys: [17329328402.916935, 1416678713.5300913, 17652794612.794613, 7604645133.216692, 0.0, 14390667673.094078, 2954099272.7977037, 11592559630.745419, 32645579078.455795, 9947831036.690937, 46536158881.61545, 34354197722.991238, 0.0, 0.0, 0.0, 38197750557.80702, 24127381500.230095, 1017768157.8615314, 57964400221.11664, 31782253542.471775, 0.0, 18619008301.14973, 34440234840.08704, 3447151210.8124547, 7943531907.237485, 17170067136.073355, 24023047624.502422, 0.0, 10437746366.71312, 28829803759.837784, 41171082208.58896, 9776020883.833675, 1908557855.5079792, 53291455434.85166, 0.0, 20546213382.97247, 4479275507.80666, 1765056600.5975676, 33790968781.470295, 41991330029.533966, 0.0, 17410252791.4989, 18001304721.030045, 0.0, 63219594543.67322, 3845885961.333034, 21260126213.346172, 22295303654.485054, 0.0, 5843480199.226777, 8007835425.516682, 5901568853.681529, 4940287396.937574, 0.0, 3068310686.0037675, 1319486337.353794, 1162970100.192844, 0.0, 0.0, 4756039868.917892, 0.0, 1293576074.5864959, 0.0, 16028676793.732683, 35094373091.243774, 31952950139.031727, 46012879161.86715, 32897792070.27727, 30537342555.515106, 27851548856.203724, 18385587165.21282, 42718378571.06482, 18283004228.237656, 34900183058.74522, 36558040617.10102, 16655299209.78438, 25611724116.874786, 44143598379.203285, 34057115017.660667, 55953895410.8858, 57232776147.91567, 17609807708.45579, 32877162453.45875, 32029812905.689198, 42493328605.44045, 16867626477.921661, 36334768484.42847, 41351710539.28818, 31426246581.50077, 16614065873.125902, 19646372195.41899, 33314567116.759335, 32980570080.5976, 17032706598.984772, 15503165831.931843, 23260982170.091232, 9064551613.844376, 21508699776.9288, 4588050493.338292, 10487333099.964994, 31392141306.788418, 31658708533.041477, 13998745077.097656, 13896706646.345503, 14793679458.239279, 26411662101.319233, 44558631679.59206, 29626021543.351585, 10073018084.007782, 5313651191.810932, 22214416609.28976, 21811253250.130005, 28541417440.713146, 9685272248.649147, 18135570208.62609, 35408416698.324265, 18451099771.24758, 11824267027.51466, 25512798053.527977, 13964721158.648243, 13478057166.728256, 14539323349.97227, 9107360924.13254, 28918257032.54275, 13049902770.647627, 9264982715.013088, 9645404162.354836, 0.0, 20915570847.981647, 19567091973.595203, 12291360919.00129, 5520164776.952285, 22808766110.17456, 9004710277.163528, 0.0, 26299050067.404457, 65793003921.56863, 52768497200.7297, 24680361293.35962, 57964400221.11664, 0.0, 1567360605.0754287, 0.0, 13083282124.865479, 8879746795.245, 28198897404.86755, 34570813929.52813, 23535078416.519375, 0.0, 3341781995.2036076, 861689541.0099773, 0.0, 15768060150.375938, 35538925605.82952, 21513664341.403366, 28529769071.183216, 6568687453.995897, 998385893.1680744, 13058231631.382317, 9760437489.091862, 0.0, 41807166708.19836, 3315340837.2328315, 1467735602.7812867, 18824576993.851265, 17138145340.87891, 0.0, 0.0, 1051867028.96688, 0.0, 48438664972.86061, 28740905197.519444, 0.0, 28538504456.69184, 31365144886.89475, 0.0, 0.0, 31875244138.769623, 0.0, 12315903218.2288, 9620625272.381126, 26303997993.164215, 39135096804.292046, 0.0, 22881558058.97275, 23625888582.211456, 5283496882.282548, 8151956697.083661, 21161443959.536842, 0.0, 0.0, 830461512.2649523, 16447283493.127853, 4919398783.727517, 41907418694.11001, 15999328641.452578, 4179987542.6663675, 30540677904.394367, 0.0, 1151142825.7767043, 0.0, 32134104577.667118, 16632842923.424673, 44610763667.30483, 9357168512.7553, 56009935234.025505, 1945017586.8968923, 1271024321.654333, 7353590181.897875, 12544650815.014206, 17973149358.301373, 24576960037.501465, 9418735052.715492, 9325441892.522844, 10332961334.26949, 26086413533.60077, 3732118451.025057, 0.0, 0.0, 0.0, 0.0, 19523373751.949173, 26387568417.74143, 0.0, 21738339941.434086, 49142401874.63386, 9293517831.226528, 26812657418.653713, 4988023190.12933, 30488507668.823143, 0.0, 0.0, 31755784373.10721, 14407227136.109917, 15997497949.92086, 1028857937.625409, 4468657209.369224, 1397290904.6086602, 65022928455.15852, 25722457990.923588, 8524921494.700257, 1172326819.0152497, 29418229002.279507, 59337964207.39903, 0.0, 1087686486.8509429, 34355604701.642292, 25449329530.975063, 32662103336.837597, 11402522836.015657, 2451547741.5131392, 0.0, 48779484793.8594, 27155508076.786118, 23201150569.75329, 6776263793.075593, 37940334690.18544, 19164762057.069748, 0.0, 5876309429.57416, 0.0, 17192236591.314327, 23757704834.461468, 22535482484.418655, 29347215225.30087, 0.0, 0.0, 32443564356.435642, 0.0, 13976820287.24716, 38958796210.29166, 18639280079.99111, 869740050.7622634, 11244481381.196215, 0.0, 0.0, 0.0, 1558968716.954693, 0.0, 19107140742.09052, 1604400497.274553, 9223318306.761957, 16627567888.99901, 15525833796.039238, 0.0, 0.0, 2113079335.4912655, 0.0, 12479704840.965218, 13620302326.714186, 19511113178.583057, 29997882992.418823, 0.0, 55097589490.9688, 0.0, 15814135168.253368, 0.0, 12446744613.923674, 19894246549.35256, 0.0, 0.0, 14364792711.954382, 1441091494.4313788, 34424688115.56139, 6694444843.464451, 27674214832.409607, 0.0, 7969946699.856537, 11123409446.521866, 33522250639.386192, 13540277306.990784, 10155330920.184498, 19206887235.26045, 21206916776.216, 1646142011.6485343, 56235221559.29476, 10029781077.752668, 0.0, 8474283001.141541, 1534626853.6575549, 26212761702.393604, 3450383965.1860595, 0.0, 26336204947.883965, 11961170364.455599, 10400347149.03852, 0.0, 38666088960.59, 42534266301.59213, 18008647302.54825, 0.0, 1248624350.280131, 0.0, 0.0, 21872103877.141293, 16186724297.622723, 0.0, 30006467305.766205, 4942266632.102373, 27851548856.203724, 0.0, 10761662112.40683, 0.0, 4361660929.879476, 1237438505.0324457, 0.0, 0.0, 0.0, 9348617534.631289, 0.0, 9040130182.233572, 4394242011.524359, 0.0, 6296099373.2878, 20589077878.40856, 9405534376.821995, 7689621413.511779, 16526997261.461475, 29674229721.60317, 59995765984.83765, 0.0, 22433032037.225224, 0.0, 42317550320.33496, 19175276018.927013, 70191682704.3762, 24653523775.93605, 13276895318.286852, 0.0, 26415820632.32145, 0.0, 2211427516.9377584, 48063988999.025955, 32059191316.976223, 0.0, 7544594242.132623, 0.0, 20425147309.47163, 5163491320.940539, 0.0, 1446566120.2487333, 28961187640.255478, 0.0, 0.0, 14908310229.61541, 0.0, 1467494244.5086665, 0.0, 32297416547.953644, 35953231613.23504, 54221498287.11783, 22206771674.38782, 0.0, 15674074627.702312, 8391377154.460972, 18326141477.694763, 1375659737.482535, 26801520815.36151, 3067603800.2179494, 10407831362.671993, 32560680045.02581, 0.0, 22410857310.78518, 36198360231.29369, 14106324516.118181, 0.0, 0.0, 16868304846.169313, 1460750487.1427402, 1189559633.9121876, 43611167143.228485, 14964959414.860403, 42086132851.69576, 4975095485.493322, 0.0, 10783519944.466585, 0.0, 47576043557.168785, 40557984818.449936, 4393620598.448622, 15013706083.439228, 55308287729.94, 11213367375.58315, 0.0, 0.0, 31130025605.81883, 58020528427.16835, 0.0, 1982405418.371133, 22750001356.00575, 25729558629.573967, 15307678832.116789, 5810452237.637753, 1093620876.893132, 0.0, 0.0, 0.0, 5328265453.898727, 17014396689.856602, 9766119098.899818, 54358527734.5775, 30264117180.171726, 1389070062.808308, 12940190664.239656, 16510407809.793736, 1450074417.2378328, 1234441179.197318, 12351627770.006626, 0.0, 35965563368.20442, 3571216075.267673, 23985954879.478455, 0.0, 0.0, 32570794020.57853, 42056592800.561516, 30476323342.415985, 0.0, 0.0, 27448735316.25274, 0.0, 0.0, 3675699550.429852, 14430524160.946827, 40510976964.311584, 41601904384.05079, 23603286437.816547, 0.0, 0.0, 0.0, 0.0, 0.0, 2401582616.41306, 20998292823.34977, 12965791832.82327, 15426757636.500725, 53485131344.04489, 3786344330.148184, 17649451913.568558, 29081671000.17334, 16910129618.803797, 0.0, 0.0, 0.0, 9457707224.67755, 3770584560.062928, 2810206864.2066298, 1434455209.8687742, 5340137249.659423, 1376958141.0770948, 8196642629.6144285, 14753351272.445875, 14017224496.616257, 0.0, 9943114524.80857, 0.0, 6667573840.333195, 15475137897.319536, 0.0, 1707587301.9104133, 19022649553.267723, 0.0, 6105734811.375001, 3058053603.1963606, 0.0, 19780720618.75118, 65342015890.32559, 0.0, 3216885507.4242234, 13700383805.059696, 0.0, 28675080330.89492, 9419263850.524378, 0.0, 15837423301.30081, 11417577003.17132, 23599302312.49648, 8607849937.91879, 8790878604.963112, 20270661865.983616, 0.0, 17042741919.099567, 22533061136.778767, 3158194974.6624804, 39869809885.931564, 0.0, 17026829317.798933, 15685798163.765215, 50336681668.16682, 1275932886.048956, 7112304887.871467, 2807498167.6277556, 0.0, 0.0, 11258818634.490719, 34407744052.502045, 13902694819.185259, 0.0, 22674977699.689144, 33108134348.975807, 11307839965.49121, 1712492038.346589, 0.0, 7447735565.953139, 0.0, 23517923126.524433, 28466838604.58803, 0.0, 0.0, 7700986881.363089, 1630518100.976724, 17204224861.051292, 36415210974.12746, 63300694234.83249, 13545524713.785141, 16081837352.862238, 5557136043.245536, 0.0, 48629611594.2029, 70062707759.1247, 0.0, 9432927391.514578, 1323007431.5202441, 1721297979.6528926, 845822767.1967969, 0.0, 6033797751.515892, 0.0, 36418372840.14934, 0.0, 25982184228.458153, 14491100055.27916, 17946233660.65507, 0.0, 32094762214.48521, 0.0, 0.0, 0.0, 1789963021.2078602, 21290883248.730965, 56610932649.48037, 0.0, 15679054988.598558, 5502891629.493571, 7784022938.376312, 8868481535.907982, 0.0, 38453394453.35778, 0.0, 33670257686.441357, 16802756189.407902, 1101086830.9689074, 0.0, 0.0, 0.0, 44379473071.63263, 28352343934.836246, 28887385929.267536, 1530675707.4847682, 0.0, 0.0, 0.0, 25735873600.245438, 7806260934.301135, 1548982561.3602288, 9207828501.805649, 26720417914.25113, 13864780258.830141, 0.0, 22169211659.927586, 0.0, 12279485903.328747, 35044525212.01488, 24562567345.982666, 23269370319.001385, 0.0, 0.0, 3295077382.355252, 1505906682.9190354, 0.0, 1936562550.4998038, 13033479382.24418, 5942918676.896701, 11708410797.53231, 0.0, 2983029824.5801196, 3620914141.174338, 5180839447.614812, 2381706368.359785, 0.0, 0.0, 4695501869.556456, 15321098772.647573, 0.0, 0.0, 0.0, 24235425996.013058, 18793368581.414104, 13236671190.07795, 7693641374.629699, 13599546066.177067, 0.0, 0.0, 1189470236.3312294, 1158697126.5344234, 1557001078.3882458, 6377617613.964663, 17243834152.15738]
x_train: [[5.044394 1.       5.044394 ... 1.       0.       0.      ]
 [4.087463 1.       4.087463 ... 1.       0.       0.      ]
 [1.       1.       1.       ... 1.       0.       0.      ]
 ...
 [1.       1.       1.       ... 1.       0.       0.      ]
 [6.022368 1.       6.022368 ... 1.       0.       0.      ]
 [2.321928 1.       2.321928 ... 1.       0.       0.      ]]
x_train shape: (640, 252)
y_train: [0.24688578 0.020183   0.25149411 0.10834111 0.         0.20501956
 0.04208617 0.16515574 0.46509184 0.14172379 0.6629868  0.48943402
 0.         0.         0.         0.54419198 0.34373562 0.01449984
 0.82580155 0.4527923  0.         0.26525947 0.49065977 0.04911054
 0.11316913 0.24461683 0.34224921 0.         0.14870346 0.41072963
 0.58655215 0.13927606 0.02719066 0.7592275  0.         0.29271578
 0.0638149  0.02514624 0.48140987 0.59823797 0.         0.24803869
 0.25645923 0.         0.90067074 0.05479119 0.30288669 0.31763455
 0.         0.08325032 0.11408525 0.08407789 0.0703828  0.
 0.04371331 0.01879833 0.01656849 0.         0.         0.06775788
 0.         0.01842919 0.         0.22835578 0.49997908 0.45522416
 0.65553179 0.46868505 0.43505643 0.39679272 0.26193399 0.60859602
 0.26047252 0.49721251 0.52083152 0.23728309 0.36488261 0.6289007
 0.48520158 0.79715848 0.81537832 0.25088169 0.46839114 0.45631921
 0.6053898  0.24030805 0.51765063 0.58912551 0.44772038 0.23669565
 0.27989601 0.47462272 0.46986436 0.2426599  0.22086899 0.33139229
 0.12913997 0.30642804 0.06536459 0.14940991 0.44723449 0.45103219
 0.19943595 0.19798224 0.21076115 0.37627908 0.63481356 0.42207311
 0.14350729 0.07570201 0.31648218 0.31073843 0.40662107 0.13798319
 0.25837207 0.50445317 0.26286732 0.16845681 0.36347324 0.19895122
 0.19201787 0.20713741 0.12974986 0.4119898  0.18591808 0.13199545
 0.1374152  0.         0.29797791 0.27876653 0.17511136 0.07864414
 0.3249497  0.12828743 0.         0.37467473 0.93733333 0.75177706
 0.35161376 0.82580155 0.         0.02232972 0.         0.18639362
 0.12650711 0.40174129 0.49252009 0.33529725 0.         0.04760937
 0.01227623 0.         0.22464286 0.50631249 0.30649877 0.40645512
 0.09358213 0.01422371 0.18603674 0.13905405 0.         0.59561425
 0.04723267 0.02091039 0.26818814 0.24416205 0.         0.
 0.01498564 0.         0.69009123 0.40946312 0.         0.40657957
 0.44684988 0.         0.         0.45411711 0.         0.17546101
 0.13706218 0.37474523 0.55754607 0.         0.32598674 0.336591
 0.07527241 0.1161385  0.30148079 0.         0.         0.01183134
 0.23431955 0.07008521 0.59704251 0.22793767 0.05955104 0.43510394
 0.         0.01639999 0.         0.45780502 0.23696316 0.63555626
 0.13330879 0.79795687 0.02771009 0.0181079  0.10476441 0.1787199
 0.25605811 0.35014063 0.13418591 0.13285679 0.14721062 0.37164536
 0.05317038 0.         0.         0.         0.         0.27814369
 0.37593583 0.         0.30969966 0.70011716 0.13240198 0.38199195
 0.07106288 0.43436069 0.         0.         0.4524152  0.20525547
 0.22791159 0.01465783 0.06366363 0.01990679 0.9263623  0.3664602
 0.12145202 0.01670179 0.41911275 0.8453703  0.         0.01549595
 0.48945407 0.36256902 0.46532726 0.16244835 0.03492647 0.
 0.69494679 0.38687644 0.33053988 0.09653941 0.54052465 0.27303466
 0.         0.08371803 0.         0.24493267 0.33846895 0.32105631
 0.41810104 0.         0.         0.4622138  0.         0.1991236
 0.55503437 0.26554827 0.01239093 0.16019678 0.         0.
 0.         0.02221016 0.         0.27221374 0.02285742 0.13140187
 0.23688801 0.22119193 0.         0.         0.03010441 0.
 0.17779464 0.19404439 0.27796902 0.42737091 0.         0.78495895
 0.         0.22529927 0.         0.17732506 0.28342741 0.
 0.         0.20465092 0.0205308  0.49043828 0.09537376 0.3942663
 0.         0.11354546 0.1584719  0.47758152 0.1929043  0.14467998
 0.2736348  0.30212863 0.0234521  0.80116645 0.1428913  0.
 0.12073059 0.02186337 0.37344541 0.04915659 0.         0.37520407
 0.17040723 0.14817065 0.         0.55086425 0.60597303 0.25656384
 0.         0.01778878 0.         0.         0.31160535 0.23060744
 0.         0.4274932  0.070411   0.39679272 0.         0.1533182
 0.         0.06213928 0.01762942 0.         0.         0.
 0.13318697 0.         0.12879204 0.06260346 0.         0.08969865
 0.29332646 0.13399785 0.10955175 0.23545521 0.42275991 0.85474181
 0.         0.31959673 0.         0.60288554 0.27318445 1.
 0.35123141 0.18915197 0.         0.37633833 0.         0.03150555
 0.68475334 0.45673775 0.         0.10748559 0.         0.29099099
 0.07356272 0.         0.0206088  0.41260142 0.         0.
 0.21239426 0.         0.02090695 0.         0.46013168 0.51221498
 0.77247754 0.31637326 0.         0.22330387 0.11954945 0.26108708
 0.01959861 0.38183329 0.04370324 0.14827727 0.46388231 0.
 0.31928081 0.51570726 0.2009686  0.         0.         0.24031772
 0.02081088 0.0169473  0.62131531 0.21320132 0.5995886  0.0708787
 0.         0.1536296  0.         0.67780172 0.57781753 0.0625946
 0.2138958  0.7879607  0.15975351 0.         0.         0.4435002
 0.82660119 0.         0.02824274 0.32411249 0.36656136 0.21808394
 0.08277978 0.01558049 0.         0.         0.         0.07591021
 0.24239904 0.13913499 0.77442976 0.43116386 0.01978967 0.18435504
 0.23521886 0.02065878 0.01758672 0.17596996 0.         0.51239067
 0.05087805 0.34172076 0.         0.         0.4640264  0.59916775
 0.4341871  0.         0.         0.39105396 0.         0.
 0.0523666  0.20558738 0.57714782 0.59268994 0.33626899 0.
 0.         0.         0.         0.         0.03421463 0.29915642
 0.18471977 0.21978042 0.76198674 0.05394292 0.25144649 0.41431791
 0.24091358 0.         0.         0.         0.13474114 0.0537184
 0.04003618 0.02043626 0.07607935 0.01961711 0.11677513 0.2101866
 0.19969922 0.         0.14165659 0.         0.09499094 0.22046968
 0.         0.02432749 0.27101002 0.         0.08698659 0.04356718
 0.         0.28181004 0.93090824 0.         0.04583001 0.19518529
 0.         0.40852533 0.13419345 0.         0.22563105 0.16266282
 0.33621223 0.12263347 0.12524103 0.28879008 0.         0.24280287
 0.32102181 0.04499386 0.56801331 0.         0.24257617 0.2234709
 0.71713171 0.01817784 0.10132689 0.03999759 0.         0.
 0.16040104 0.49019688 0.19806755 0.         0.32304365 0.47168173
 0.16109943 0.02439736 0.         0.10610567 0.         0.33505285
 0.40555857 0.         0.         0.10971367 0.02322951 0.24510347
 0.51879667 0.90182614 0.19297906 0.22911315 0.07917086 0.
 0.69281159 0.99816253 0.         0.13438811 0.01884849 0.02452282
 0.01205019 0.         0.08596172 0.         0.51884171 0.
 0.37016044 0.20645039 0.25567465 0.         0.45724452 0.
 0.         0.         0.02550107 0.30332487 0.8065191  0.
 0.22337483 0.07839806 0.11089666 0.12634662 0.         0.54783406
 0.         0.47969013 0.23938386 0.01568686 0.         0.
 0.         0.63226114 0.4039274  0.41154998 0.02180708 0.
 0.         0.         0.36665133 0.11121347 0.02206789 0.13118119
 0.38067784 0.1975274  0.         0.31583816 0.         0.17494218
 0.49926891 0.34993558 0.33151179 0.         0.         0.04694399
 0.0214542  0.         0.02758963 0.1856841  0.08466699 0.16680624
 0.         0.04249834 0.05158609 0.07380988 0.03393146 0.
 0.         0.06689542 0.21827513 0.         0.         0.
 0.3452749  0.26774353 0.18857891 0.10960902]
y_train shape: (640,)
feas: [[4.087463  1.        4.087463  ... 1.        0.        0.       ]
 [2.321928  1.        2.321928  ... 1.        0.        0.       ]
 [1.5849625 1.        1.5849625 ... 1.        0.        0.       ]
 ...
 [6.022368  1.        6.022368  ... 1.        0.        0.       ]
 [5.044394  1.        5.044394  ... 1.        0.        0.       ]
 [3.169925  1.        3.169925  ... 1.        0.        0.       ]]
feas shape: (128, 252)
predict count: 10
